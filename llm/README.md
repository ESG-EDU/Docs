<img src="./images/llm-0.png" width="200">

## (1) LLM (Large Language Model)

### 개념

> LLM은 대규모 텍스트 데이터로 학습된 **거대한 딥러닝 언어 모델**입니다. 사람의 언어를 이해하고 생성하며, 질문 답변·요약·번역·코딩·추론 등 다양한 작업이 가능합니다.

### 구성 요소

- **Transformer 구조**: Self-Attention을 사용해 문맥을 파악
- **수십억~수천억 개의 파라미터**
- **대규모 프리트레이닝 데이터**: 웹·책·문서 등

### 동작 방식

1. 사전학습(Pre-training):
	- 방대한 텍스트에서 다음 단어 예측
2. 추론(Inference):
  - 사용자가 입력한 문맥을 바탕으로 확률적으로 가장 적합한 단어/문장 생성

### 장점

- 범용적 활용 가능
- 자연스러운 언어 생성
- 많은 작업에 Zero-shot/ Few-shot 가능

### 단점

- 최신 정보 부족 가능
- 잘못된 정보(할루시네이션) 생성 가능
- 특정 도메인 전문성 부족

### 적용 예시

- 일반적인 대화형 서비스
- 요약/번역 등 범용 언어처리
- 오픈도메인 Q&A

## (2) RAG (Retrieval-Augmented Generation)

### 개념

- RAG는 **LLM + 외부 지식 검색 시스템**의 결합 모델입니다.
- LLM이 자체 지식만 사용하는 것이 아니라, **벡터DB 등에서 관련 문서를 검색해 답변을 생성**합니다.

### 구성 요소

- **벡터 임베딩 모델**
- **벡터 데이터베이스** (FAISS, Milvus, Pinecone 등)
- **Retriever**: 유사도 기반 관련 문서 검색
- **LLM Generator**: 검색된 문서를 바탕으로 답변 생성

### 동작 방식

1. 사용자 질문 → 임베딩으로 변환
2. 벡터DB에서 관련 문서 검색
3. 검색된 문서를 LLM에 전달
4. LLM이 문서를 참고해 답변 생성

### 장점

- 최신·정확한 정보 제공 가능
- 도메인 문서 기반의 신뢰 높은 답변
- 할루시네이션 감소

### 단점

- 문서 품질에 따라 성능 좌우
- 검색 품질 개선 필요
- 설정이 다소 복잡(임베딩/DB/LLM 연동 등)

## 적용 예시

- 기업 문서 Q&A
- 기술 매뉴얼 기반 챗봇
- 법률/의료/금융 등 전문 문서 기반 질의응답
- 최신 정보 반영이 필요한 경우

## (3) Fine-Tuning

### 개념

> 파인튜닝은 **사전 학습된 LLM을 특정 목적·도메인에 맞추어 추가 학습시키는 과정**입니다.

- “LLM에게 특정 문체·규칙·정책·작업 능력을 추가로 학습시키는 것”

### 종류

1. **Supervised Fine-Tuning (SFT)**

  - 정답이 있는 데이터로 원하는 출력 패턴 학습

2. **Instruction Tuning**

  - 다양한 ‘명령 → 응답’ 쌍으로 모델을 지시 이해 능력 강화

3. **LoRA, QLoRA**

  - 파라미터 효율적 파인튜닝 방식(PET)
  - GPU 비용 적게 들고, 모델 전체가 아닌 일부 레이어만 학습

### 동작 방식

1. 사전학습된 LLM 불러오기
2. 도메인 또는 작업 관련 데이터 준비
3. LLM 출력이 원하는 패턴을 따르도록 추가 학습
4. 새로운 모델 생성(예: base → specialized)

### 장점

- 특정 도메인에 최적화
- 스타일·톤·포맷 통일
- 반복 작업 자동화 성능 향상
- 매우 높은 정확도 가능

### 단점

- 데이터 준비 비용
- 잘못 학습하면 성능 저하 가능
- 변경·업데이트가 필요할 수 있음
- 운영·배포 복잡성 증가

### 적용 예시

- 특정 말투, 규칙, 브랜드 톤을 강제하고 싶을 때
- 독자적인 특별 기능이 필요할 때
- 의학/법률/금융 등의 전문 질의응답
- 자동 분류/추출/요약 등 반복 태스크 최적화
- RAG만으로는 해결되지 않는 패턴 학습이 필요할 때

## (4) LLM vs RAG vs Fine-Tuning 차이 보기

| 항목 | `LLM` | `RAG` | `Fine-Tuning` |
| :---: | :---: | :---: | :---: |
| 목적 | 범용 언어 이해/생성 | 외부 지식 기반 정확한 답변 | 특정 도메인/작업 능력 최적화 |
| 해결 방식 | 내재 지식만 사용 | 문서 검색 + 생성 | 모델 자체를 재학습 |
| 최신성 | 낮음 | 높음(문서 최신화 가능) | 데이터에 따라 다름 |
| 개발 난이도 | 낮음 | 중간 | 중~높음 |
| 주요 문제 | 할루시네이션 | 검색 품질 의존 | 데이터 비용·관리 |

> 참고 사항

- **기업 문서 Q&A** → RAG
- **특정 말투/포맷/브랜드 톤 강제** → Fine-Tuning
- **완전히 새로운 작업 수행(예: 특정 규칙 기반 분류)** → Fine-Tuning
- **최신 정보가 필요하거나 사내 문서 기반** → RAG
- **일반적 대화·요약·번역** → LLM만으로도 충분
